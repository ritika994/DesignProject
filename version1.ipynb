{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/vzdXqi8D0UGvqEBJyyMG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omnimanwani/DesignProject/blob/main/version1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9TOO5q_xDyg",
        "outputId": "8719ecb6-107a-463a-ff18-e54740b578f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (24.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "# import pandas as pd\n",
        "# import logging\n",
        "# from tqdm import tqdm\n",
        "# import re\n",
        "# from typing import Dict, List, Tuple, Optional\n",
        "# from dataclasses import dataclass\n",
        "# import torch\n",
        "# from transformers import pipeline\n",
        "\n",
        "# @dataclass\n",
        "# class ProcessingResult:\n",
        "#     entities: List[Dict[str, str]]\n",
        "#     intent: str\n",
        "#     confidence: float\n",
        "#     analysis_details: Dict\n",
        "\n",
        "# class PromptMovieProcessor:\n",
        "#     \"\"\"Process movie dialogue data using prompts and LLMs.\"\"\"\n",
        "\n",
        "#     def __init__(self):\n",
        "#         \"\"\"Initialize the processor with models and prompts.\"\"\"\n",
        "#         self._initialize_logging()\n",
        "#         self._setup_models()\n",
        "#         self._initialize_prompts()\n",
        "\n",
        "#     def _initialize_logging(self) -> None:\n",
        "#         \"\"\"Set up logging configuration.\"\"\"\n",
        "#         self.logger = logging.getLogger(__name__)\n",
        "#         self.logger.setLevel(logging.INFO)\n",
        "\n",
        "#         # Create console handler with formatting\n",
        "#         console_handler = logging.StreamHandler()\n",
        "#         console_handler.setLevel(logging.INFO)\n",
        "#         formatter = logging.Formatter(\n",
        "#             '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "#         )\n",
        "#         console_handler.setFormatter(formatter)\n",
        "#         self.logger.addHandler(console_handler)\n",
        "\n",
        "#         # Also log to file\n",
        "#         file_handler = logging.FileHandler('movie_processor.log')\n",
        "#         file_handler.setLevel(logging.INFO)\n",
        "#         file_handler.setFormatter(formatter)\n",
        "#         self.logger.addHandler(file_handler)\n",
        "\n",
        "#     def _initialize_prompts(self) -> None:\n",
        "#         \"\"\"Initialize system and task-specific prompts.\"\"\"\n",
        "#         self.entity_prompt_template = \"\"\"Analyze this movie-related message and identify entities. Focus on:\n",
        "\n",
        "# PERSON: Actors, directors, characters\n",
        "# WORK_OF_ART: Movies, TV shows, series titles\n",
        "# ORG: Studios, production companies\n",
        "# GENRE: Movie genres\n",
        "# ATTRIBUTE: Movie qualities or characteristics\n",
        "\n",
        "# Message: \"{text}\"\n",
        "\n",
        "# List all entities found in this format:\n",
        "# Entity: [exact text from message]\n",
        "# Type: [entity type]\n",
        "# Explanation: [why this is that type of entity]\n",
        "\n",
        "# Only include entities you're confident about.\"\"\"\n",
        "\n",
        "#         self.intent_prompt_template = \"\"\"Analyze this movie-related message and identify the main conversational intent. Consider these categories:\n",
        "\n",
        "# 1. RECOMMENDATION_REQUEST: Asking for movie suggestions\n",
        "# Example: \"Can you suggest movies like Inception?\"\n",
        "\n",
        "# 2. PREFERENCE_QUESTION: Asking about movie preferences\n",
        "# Example: \"What kind of movies do you enjoy?\"\n",
        "\n",
        "# 3. OPINION_SHARING: Expressing thoughts about movies\n",
        "# Example: \"I loved The Dark Knight, it was amazing!\"\n",
        "\n",
        "# 4. INFORMATION_REQUEST: Asking for movie information\n",
        "# Example: \"Who directed Pulp Fiction?\"\n",
        "\n",
        "# 5. CRITIQUE: Detailed movie criticism\n",
        "# Example: \"The pacing was slow and the plot had holes...\"\n",
        "\n",
        "# 6. RECOMMENDATION_GIVING: Suggesting movies\n",
        "# Example: \"You should watch Shawshank Redemption\"\n",
        "\n",
        "# 7. FACTUAL_STATEMENT: Stating movie facts\n",
        "# Example: \"Titanic won 11 Academy Awards\"\n",
        "\n",
        "# 8. GENERAL_DISCUSSION: General movie chat\n",
        "# Example: \"Movies these days are so different\"\n",
        "\n",
        "# Message: \"{text}\"\n",
        "\n",
        "# Identify:\n",
        "# 1. Primary Intent: [category]\n",
        "# 2. Confidence (0-1): [score]\n",
        "# 3. Reasoning: [brief explanation]\"\"\"\n",
        "\n",
        "#         self.movie_context_prompt = \"\"\"Consider this message in the context of a movie recommendation conversation:\n",
        "\n",
        "# Previous context about movies: {context}\n",
        "# Current message: \"{text}\"\n",
        "\n",
        "# Analyze:\n",
        "# 1. Are there implicit movie references?\n",
        "# 2. Any indirect mentions of movie elements?\n",
        "# 3. What aspects of movies are being discussed?\n",
        "\n",
        "# Format findings as:\n",
        "# Referenced Movies: [list]\n",
        "# Implied Genres: [list]\n",
        "# Discussion Topics: [list]\"\"\"\n",
        "\n",
        "#     def _setup_models(self) -> None:\n",
        "#         \"\"\"Set up necessary models from Hugging Face.\"\"\"\n",
        "#         self.logger.info(\"Setting up models...\")\n",
        "\n",
        "#         try:\n",
        "#             # Use BERT for zero-shot classification\n",
        "#             self.classifier = pipeline(\n",
        "#                 \"zero-shot-classification\",\n",
        "#                 model=\"facebook/bart-large-mnli\",\n",
        "#                 device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#             )\n",
        "\n",
        "#             # Use RoBERTa for NER\n",
        "#             self.ner_pipeline = pipeline(\n",
        "#                 \"ner\",\n",
        "#                 model=\"jean-baptiste/roberta-large-ner-english\",\n",
        "#                 device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#             )\n",
        "\n",
        "#             self.logger.info(\"Models loaded successfully\")\n",
        "#         except Exception as e:\n",
        "#             self.logger.error(f\"Error loading models: {str(e)}\")\n",
        "#             raise\n",
        "\n",
        "#     def process_batch(self, texts: List[str], batch_size: int = 32) -> List[ProcessingResult]:\n",
        "#         \"\"\"Process a batch of texts with progress bar.\"\"\"\n",
        "#         results = []\n",
        "#         self.logger.info(f\"Processing batch of {len(texts)} texts\")\n",
        "\n",
        "#         try:\n",
        "#             for i in tqdm(range(0, len(texts), batch_size)):\n",
        "#                 batch = texts[i:i + batch_size]\n",
        "#                 batch_results = [\n",
        "#                     self.extract_entities_and_intents(text)\n",
        "#                     for text in batch\n",
        "#                 ]\n",
        "#                 results.extend(batch_results)\n",
        "\n",
        "#             self.logger.info(f\"Successfully processed {len(results)} texts\")\n",
        "#             return results\n",
        "\n",
        "#         except Exception as e:\n",
        "#             self.logger.error(f\"Error in batch processing: {str(e)}\")\n",
        "#             raise\n",
        "\n",
        "#     def save_results(self, results: List[ProcessingResult], output_file: str) -> None:\n",
        "#         \"\"\"Save processing results to JSON file.\"\"\"\n",
        "#         try:\n",
        "#             output_data = [\n",
        "#                 {\n",
        "#                     \"entities\": result.entities,\n",
        "#                     \"intent\": result.intent,\n",
        "#                     \"confidence\": result.confidence,\n",
        "#                     \"analysis_details\": result.analysis_details\n",
        "#                 }\n",
        "#                 for result in results\n",
        "#             ]\n",
        "\n",
        "#             with open(output_file, 'w') as f:\n",
        "#                 json.dump(output_data, f, indent=2)\n",
        "\n",
        "#             self.logger.info(f\"Results saved to {output_file}\")\n",
        "\n",
        "#         except Exception as e:\n",
        "#             self.logger.error(f\"Error saving results: {str(e)}\")\n",
        "#             raise\n",
        "\n",
        "#     def load_data(self, input_file: str) -> List[str]:\n",
        "#         \"\"\"Load input data from file (CSV or JSON).\"\"\"\n",
        "#         try:\n",
        "#             if input_file.endswith('.csv'):\n",
        "#                 df = pd.read_csv(input_file)\n",
        "#                 texts = df['text'].tolist()  # Assumes 'text' column\n",
        "#             elif input_file.endswith('.json'):\n",
        "#                 with open(input_file, 'r') as f:\n",
        "#                     data = json.load(f)\n",
        "#                 texts = [item['text'] for item in data]  # Assumes list of dicts with 'text' key\n",
        "#             else:\n",
        "#                 raise ValueError(\"Unsupported file format. Use CSV or JSON.\")\n",
        "\n",
        "#             self.logger.info(f\"Loaded {len(texts)} texts from {input_file}\")\n",
        "#             return texts\n",
        "\n",
        "#         except Exception as e:\n",
        "#             self.logger.error(f\"Error loading data: {str(e)}\")\n",
        "#             raise\n",
        "\n",
        "#     def extract_entities_and_intents(self,\n",
        "#                                    text: str,\n",
        "#                                    context: Optional[List[str]] = None) -> ProcessingResult:\n",
        "#         \"\"\"Extract entities and classify intent using prompts and models.\"\"\"\n",
        "#         try:\n",
        "#             # 1. Entity Recognition with Prompt\n",
        "#             entity_prompt = self.entity_prompt_template.format(text=text)\n",
        "#             entity_results = self._process_with_prompt_ner(text, entity_prompt)\n",
        "\n",
        "#             # 2. Intent Classification with Prompt\n",
        "#             intent_prompt = self.intent_prompt_template.format(text=text)\n",
        "#             intent_result = self._process_with_prompt_intent(text, intent_prompt)\n",
        "\n",
        "#             # 3. Additional Context Analysis (if context provided)\n",
        "#             context_analysis = {}\n",
        "#             if context:\n",
        "#                 context_prompt = self.movie_context_prompt.format(\n",
        "#                     context=\"\\n\".join(context[-3:]),  # Use last 3 messages\n",
        "#                     text=text\n",
        "#                 )\n",
        "#                 context_analysis = self._analyze_movie_context(text, context_prompt)\n",
        "\n",
        "#             # Combine results\n",
        "#             result = ProcessingResult(\n",
        "#                 entities=entity_results['entities'],\n",
        "#                 intent=intent_result['intent'],\n",
        "#                 confidence=intent_result['confidence'],\n",
        "#                 analysis_details={\n",
        "#                     'entity_explanations': entity_results['explanations'],\n",
        "#                     'intent_reasoning': intent_result['reasoning'],\n",
        "#                     'context_analysis': context_analysis\n",
        "#                 }\n",
        "#             )\n",
        "\n",
        "#             return result\n",
        "\n",
        "#         except Exception as e:\n",
        "#             self.logger.error(f\"Error in processing: {str(e)}\")\n",
        "#             return ProcessingResult(\n",
        "#                 entities=[],\n",
        "#                 intent=\"unknown\",\n",
        "#                 confidence=0.0,\n",
        "#                 analysis_details={}\n",
        "#             )\n",
        "\n",
        "#     def _process_with_prompt_ner(self, text: str, prompt: str) -> Dict:\n",
        "#         \"\"\"Process text for NER using prompt-based approach.\"\"\"\n",
        "#         # Zero-shot NER with custom labels\n",
        "#         ner_labels = [\n",
        "#             \"PERSON - actor/director/character\",\n",
        "#             \"WORK_OF_ART - movie/show title\",\n",
        "#             \"ORG - movie studio/company\",\n",
        "#             \"GENRE - movie genre\",\n",
        "#             \"ATTRIBUTE - movie characteristic\"\n",
        "#         ]\n",
        "\n",
        "#         results = self.classifier(\n",
        "#             text,\n",
        "#             candidate_labels=ner_labels,\n",
        "#             multi_label=True\n",
        "#         )\n",
        "\n",
        "#         # Process results into entities\n",
        "#         entities = []\n",
        "#         explanations = []\n",
        "\n",
        "#         for label, score in zip(results['labels'], results['scores']):\n",
        "#             if score > 0.7:  # Confidence threshold\n",
        "#                 entity_type = label.split(' - ')[0]\n",
        "#                 # Extract the actual entity text using regex patterns\n",
        "#                 if entity_type == \"PERSON\":\n",
        "#                     matches = re.finditer(r'[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*', text)\n",
        "#                 elif entity_type == \"WORK_OF_ART\":\n",
        "#                     matches = re.finditer(r'(?:The\\s)?[A-Z][^.!?]*?(?:movie|film|show|series)?', text)\n",
        "#                 else:\n",
        "#                     matches = re.finditer(r'\\b[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*\\b', text)\n",
        "\n",
        "#                 for match in matches:\n",
        "#                     entities.append({\n",
        "#                         \"text\": match.group(),\n",
        "#                         \"type\": entity_type,\n",
        "#                         \"confidence\": score\n",
        "#                     })\n",
        "#                     explanations.append(f\"{match.group()} identified as {entity_type} with confidence {score:.2f}\")\n",
        "\n",
        "#         return {\n",
        "#             \"entities\": entities,\n",
        "#             \"explanations\": explanations\n",
        "#         }\n",
        "\n",
        "#     def _process_with_prompt_intent(self, text: str, prompt: str) -> Dict:\n",
        "#         \"\"\"Process text for intent classification using prompt-based approach.\"\"\"\n",
        "#         intent_labels = [\n",
        "#             \"RECOMMENDATION_REQUEST\",\n",
        "#             \"PREFERENCE_QUESTION\",\n",
        "#             \"OPINION_SHARING\",\n",
        "#             \"INFORMATION_REQUEST\",\n",
        "#             \"CRITIQUE\",\n",
        "#             \"RECOMMENDATION_GIVING\",\n",
        "#             \"FACTUAL_STATEMENT\",\n",
        "#             \"GENERAL_DISCUSSION\"\n",
        "#         ]\n",
        "\n",
        "#         result = self.classifier(\n",
        "#             text,\n",
        "#             candidate_labels=intent_labels\n",
        "#         )\n",
        "\n",
        "#         return {\n",
        "#             \"intent\": result['labels'][0],\n",
        "#             \"confidence\": result['scores'][0],\n",
        "#             \"reasoning\": f\"Classified as {result['labels'][0]} based on message content and pattern matching\"\n",
        "#         }\n",
        "\n",
        "#     def _analyze_movie_context(self, text: str, prompt: str) -> Dict:\n",
        "#         \"\"\"Analyze movie-specific context and references.\"\"\"\n",
        "#         # Use zero-shot classification for movie-related aspects\n",
        "#         aspect_labels = [\n",
        "#             \"discusses_plot\",\n",
        "#             \"mentions_actors\",\n",
        "#             \"compares_movies\",\n",
        "#             \"asks_for_recommendations\",\n",
        "#             \"shares_opinion\"\n",
        "#         ]\n",
        "\n",
        "#         result = self.classifier(\n",
        "#             text,\n",
        "#             candidate_labels=aspect_labels,\n",
        "#             multi_label=True\n",
        "#         )\n",
        "\n",
        "#         return {\n",
        "#             \"aspects\": [label for label, score in zip(result['labels'], result['scores']) if score > 0.5],\n",
        "#             \"confidence_scores\": dict(zip(result['labels'], result['scores']))\n",
        "#         }\n",
        "\n",
        "# def main():\n",
        "#     \"\"\"Example usage with prompts.\"\"\"\n",
        "#     processor = PromptMovieProcessor()\n",
        "\n",
        "#     # Example usage with a single text\n",
        "#     text = \"I loved Inception! Can you recommend similar mind-bending movies like what Christopher Nolan directs?\"\n",
        "#     result = processor.extract_entities_and_intents(text)\n",
        "#     print(\"\\nSingle text analysis:\")\n",
        "#     print(\"Entities found:\", json.dumps(result.entities, indent=2))\n",
        "#     print(\"Intent:\", result.intent)\n",
        "#     print(\"Confidence:\", result.confidence)\n",
        "#     print(\"Analysis details:\", json.dumps(result.analysis_details, indent=2))\n",
        "\n",
        "#     # Example batch processing\n",
        "#     texts = [\n",
        "#         \"The Dark Knight is probably Nolan's best film.\",\n",
        "#         \"Can you suggest some good sci-fi movies?\",\n",
        "#         \"I think Marvel movies are getting repetitive.\",\n",
        "#     ]\n",
        "#     print(\"\\nBatch processing example:\")\n",
        "#     results = processor.process_batch(texts, batch_size=2)\n",
        "\n",
        "#     # Save results\n",
        "#     processor.save_results(results, \"movie_analysis_results.json\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "metadata": {
        "id": "77KhFGeqL0hr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1afc8b84-97b8-4336-adb0-64fdc051a07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-07 05:09:00,042 - __main__ - INFO - Setting up models...\n",
            "2024-11-07 05:09:00,042 - __main__ - INFO - Setting up models...\n",
            "2024-11-07 05:09:00,042 - __main__ - INFO - Setting up models...\n",
            "INFO:__main__:Setting up models...\n",
            "2024-11-07 05:09:03,899 - __main__ - INFO - Models loaded successfully\n",
            "2024-11-07 05:09:03,899 - __main__ - INFO - Models loaded successfully\n",
            "2024-11-07 05:09:03,899 - __main__ - INFO - Models loaded successfully\n",
            "INFO:__main__:Models loaded successfully\n",
            "2024-11-07 05:09:16,011 - __main__ - INFO - Processing batch of 3 texts\n",
            "2024-11-07 05:09:16,011 - __main__ - INFO - Processing batch of 3 texts\n",
            "2024-11-07 05:09:16,011 - __main__ - INFO - Processing batch of 3 texts\n",
            "INFO:__main__:Processing batch of 3 texts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Single text analysis:\n",
            "Entities found: [\n",
            "  {\n",
            "    \"text\": \"Inception\",\n",
            "    \"type\": \"ATTRIBUTE\",\n",
            "    \"confidence\": 0.9421381950378418\n",
            "  },\n",
            "  {\n",
            "    \"text\": \"Can\",\n",
            "    \"type\": \"ATTRIBUTE\",\n",
            "    \"confidence\": 0.9421381950378418\n",
            "  },\n",
            "  {\n",
            "    \"text\": \"Christopher Nolan\",\n",
            "    \"type\": \"ATTRIBUTE\",\n",
            "    \"confidence\": 0.9421381950378418\n",
            "  }\n",
            "]\n",
            "Intent: PREFERENCE_QUESTION\n",
            "Confidence: 0.23613303899765015\n",
            "Analysis details: {\n",
            "  \"entity_explanations\": [\n",
            "    \"Inception identified as ATTRIBUTE with confidence 0.94\",\n",
            "    \"Can identified as ATTRIBUTE with confidence 0.94\",\n",
            "    \"Christopher Nolan identified as ATTRIBUTE with confidence 0.94\"\n",
            "  ],\n",
            "  \"intent_reasoning\": \"Classified as PREFERENCE_QUESTION based on message content and pattern matching\",\n",
            "  \"context_analysis\": {}\n",
            "}\n",
            "\n",
            "Batch processing example:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:24<00:00, 12.16s/it]\n",
            "2024-11-07 05:09:40,358 - __main__ - INFO - Successfully processed 3 texts\n",
            "2024-11-07 05:09:40,358 - __main__ - INFO - Successfully processed 3 texts\n",
            "2024-11-07 05:09:40,358 - __main__ - INFO - Successfully processed 3 texts\n",
            "INFO:__main__:Successfully processed 3 texts\n",
            "2024-11-07 05:09:40,364 - __main__ - INFO - Results saved to movie_analysis_results.json\n",
            "2024-11-07 05:09:40,364 - __main__ - INFO - Results saved to movie_analysis_results.json\n",
            "2024-11-07 05:09:40,364 - __main__ - INFO - Results saved to movie_analysis_results.json\n",
            "INFO:__main__:Results saved to movie_analysis_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "from typing import Dict, List, Optional\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "import jsonlines\n",
        "import re\n",
        "\n",
        "@dataclass\n",
        "class MessageAnalysisResult:\n",
        "    message_id: int\n",
        "    conversation_id: str\n",
        "    text: str\n",
        "    time_offset: int\n",
        "    intent: str\n",
        "    confidence: float\n",
        "    entities: List[Dict[str, str]]\n",
        "    referenced_movies: List[str]\n",
        "    analysis_details: Dict\n",
        "\n",
        "class MovieDialogAnalyzer:\n",
        "    \"\"\"Analyze movie dialogue messages for intents and entities.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._initialize_logging()\n",
        "        self._setup_models()\n",
        "        self._initialize_prompts()\n",
        "\n",
        "    def _initialize_logging(self) -> None:\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        self.logger.setLevel(logging.INFO)\n",
        "\n",
        "        console_handler = logging.StreamHandler()\n",
        "        console_handler.setLevel(logging.INFO)\n",
        "        formatter = logging.Formatter(\n",
        "            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        console_handler.setFormatter(formatter)\n",
        "        self.logger.addHandler(console_handler)\n",
        "\n",
        "        file_handler = logging.FileHandler('movie_dialog_analyzer.log')\n",
        "        file_handler.setLevel(logging.INFO)\n",
        "        file_handler.setFormatter(formatter)\n",
        "        self.logger.addHandler(file_handler)\n",
        "\n",
        "    def _initialize_prompts(self) -> None:\n",
        "        self.entity_prompt_template = \"\"\"Analyze this movie-related message and identify entities. Focus on:\n",
        "\n",
        "PERSON: Actors, directors, characters\n",
        "WORK_OF_ART: Movies, TV shows, series titles\n",
        "ORG: Studios, production companies\n",
        "GENRE: Movie genres\n",
        "ATTRIBUTE: Movie qualities or characteristics\n",
        "\n",
        "Message: \"{text}\"\n",
        "\n",
        "List all entities found in this format:\n",
        "Entity: [exact text from message]\n",
        "Type: [entity type]\n",
        "Confidence: [confidence score]\n",
        "Explanation: [why this is that type of entity]\n",
        "\n",
        "Only include entities you're confident about.\"\"\"\n",
        "\n",
        "        self.intent_prompt_template = \"\"\"Analyze this movie-related message and identify the main conversational intent. Consider these categories:\n",
        "\n",
        "Intent Name: Initiate\n",
        "Intent Description: Start a dialogue with the system.\n",
        "Intent Example: [\"hello\", \"hi\", \"hey\", \"greetings\", \"start\", \"begin\"]\n",
        "\n",
        "Intent Name: Chit-chat\n",
        "Intent Description: Utterances unrelated to the recommendation goal.\n",
        "Intent Example: [\"how are you\", \"what's up\", \"nice weather\", \"that's interesting\", \"really\",\"weather\", \"nice\", \"thanks\", \"thank you\"]\n",
        "\n",
        "Intent Name: Provide Preferences\n",
        "Intent Description: Share preferences with the system.\n",
        "Intent Example: [\"like\", \"enjoy\", \"prefer\", \"favorite\", \"love\", \"hate\", \"dislike\"]\n",
        "\n",
        "Intent Name: Revise Preferences\n",
        "Intent Description: Revise previously stated preferences.\n",
        "Intent Example: [\"actually\", \"instead\", \"rather\", \"change\", \"different\", \"not that\"]\n",
        "\n",
        "Intent Name: Ask for Recommendation\n",
        "Intent Description: Obtain system suggestions.\n",
        "Intent Example: [\"recommend\", \"suggest\", \"what should\", \"can you find\", \"looking for\"]\n",
        "\n",
        "Intent Name: Obtain Explanation\n",
        "Intent Description: Learn more about why something was recommended.\n",
        "Intent Example: [\"why\", \"how come\", \"explain\", \"reason\", \"because\"]\n",
        "\n",
        "Intent Name: Obtain Details\n",
        "Intent Description: Ask about more details of a recommended object.\n",
        "Intent Example: [\"what is\", \"tell me about\", \"details\", \"more info\", \"description\"]\n",
        "\n",
        "Intent Name: Feedback on Recommendation\n",
        "Intent Description: Give feedback on the provided recommendation(s).\n",
        "Intent Example: [\"good suggestion\", \"bad suggestion\", \"not what\", \"perfect\", \"exactly\"]\n",
        "\n",
        "Intent Name: Restart\n",
        "Intent Description: Restart the dialogue.\n",
        "Intent Example: [\"start over\", \"begin again\", \"restart\", \"fresh\", \"new search\"]\n",
        "\n",
        "Intent Name: Accept Recommendation\n",
        "Intent Description: Accept one of the recommendations.\n",
        "Intent Example: [\"that works\", \"sounds good\", \"perfect\", \"i'll take\", \"great choice\"]\n",
        "\n",
        "Intent Name: Quit\n",
        "Intent Description: Terminate the conversation.\n",
        "Intent Example: [\"goodbye\", \"bye\", \"that's all\", \"done\", \"exit\", \"quit\"]\n",
        "\n",
        "Message: \"{text}\"\n",
        "\n",
        "Identify:\n",
        "1. Primary Intent: [category]\n",
        "2. Confidence (0-1): [score]\n",
        "3. Reasoning: [brief explanation]\"\"\"\n",
        "\n",
        "    def _setup_models(self) -> None:\n",
        "        \"\"\"Set up necessary models from Hugging Face.\"\"\"\n",
        "        self.logger.info(\"Setting up models...\")\n",
        "        try:\n",
        "            self.classifier = pipeline(\n",
        "                \"zero-shot-classification\",\n",
        "                model=\"facebook/bart-large-mnli\",\n",
        "                device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "            )\n",
        "\n",
        "            self.ner_pipeline = pipeline(\n",
        "                \"ner\",\n",
        "                model=\"jean-baptiste/roberta-large-ner-english\",\n",
        "                device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "            )\n",
        "            self.logger.info(\"Models loaded successfully\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading models: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _process_with_prompt_intent(self, text: str, prompt: str) -> Dict:\n",
        "        \"\"\"Process text for intent classification using prompt-based approach.\"\"\"\n",
        "        intent_labels = [\n",
        "            \"Initiate\",\n",
        "            \"Chit-chat\",\n",
        "            \"Provide Preferences\",\n",
        "            \"Revise Preferences\",\n",
        "            \"Ask for Recommendation\",\n",
        "            \"Obtain Explanation\",\n",
        "            \"Obtain Details\",\n",
        "            \"Feedback on Recommendation\",\n",
        "            \"Restart\",\n",
        "            \"Accept Recommendation\",\n",
        "            \"Quit\"\n",
        "        ]\n",
        "\n",
        "        result = self.classifier(\n",
        "            text,\n",
        "            candidate_labels=intent_labels\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"intent\": result['labels'][0],\n",
        "            \"confidence\": result['scores'][0]\n",
        "        }\n",
        "\n",
        "    def _process_dialogue(self, dialogue: Dict) -> List[MessageAnalysisResult]:\n",
        "        \"\"\"Process a single dialogue and analyze all its messages.\"\"\"\n",
        "        results = []\n",
        "        movie_mentions = dialogue.get('movieMentions', {})\n",
        "        initiator_id = dialogue.get('initiatorWorkerId')\n",
        "\n",
        "        if not initiator_id:\n",
        "            self.logger.warning(f\"No initiator ID found for dialogue {dialogue.get('conversationId', 'unknown')}\")\n",
        "            return results\n",
        "\n",
        "        # Filter only initiator's messages\n",
        "        initiator_messages = [\n",
        "            message for message in dialogue.get('messages', [])\n",
        "            if message.get('senderWorkerId') == initiator_id\n",
        "        ]\n",
        "\n",
        "        for message in initiator_messages:\n",
        "            processed_text = self._replace_movie_tokens(message.get('text', ''), movie_mentions)\n",
        "\n",
        "            if len(processed_text.strip()) < 2:\n",
        "                continue\n",
        "\n",
        "            referenced_movies = self._extract_referenced_movies(message.get('text', ''), movie_mentions)\n",
        "\n",
        "            result = self._analyze_message(\n",
        "                message_id=message.get('messageId', 0),\n",
        "                conversation_id=dialogue.get('conversationId', ''),\n",
        "                text=processed_text,\n",
        "                original_text=message.get('text', ''),\n",
        "                time_offset=message.get('timeOffset', 0),\n",
        "                referenced_movies=referenced_movies\n",
        "            )\n",
        "\n",
        "            results.append(result)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _replace_movie_tokens(self, text: str, movie_mentions: Dict[str, str]) -> str:\n",
        "        \"\"\"Replace @movieID tokens with actual movie names.\"\"\"\n",
        "        processed_text = text\n",
        "        for movie_id, movie_name in movie_mentions.items():\n",
        "            processed_text = processed_text.replace(f\"@{movie_id}\", movie_name)\n",
        "        return processed_text\n",
        "\n",
        "    def _extract_referenced_movies(self, text: str, movie_mentions: Dict[str, str]) -> List[str]:\n",
        "        \"\"\"Extract list of movies referenced in the message.\"\"\"\n",
        "        referenced_movies = []\n",
        "        for movie_id, movie_name in movie_mentions.items():\n",
        "            if f\"@{movie_id}\" in text:\n",
        "                referenced_movies.append(movie_name)\n",
        "        return referenced_movies\n",
        "\n",
        "    def _process_with_prompt_ner(self, text: str, prompt: str) -> Dict:\n",
        "        \"\"\"Process text for NER using prompt-based approach with confidence scores.\"\"\"\n",
        "        ner_labels = [\n",
        "            \"PERSON - actor/director/character\",\n",
        "            \"WORK_OF_ART - movie/show title\",\n",
        "            \"ORG - movie studio/company\",\n",
        "            \"GENRE - movie genre\",\n",
        "            \"ATTRIBUTE - movie characteristic\"\n",
        "        ]\n",
        "\n",
        "        results = self.classifier(\n",
        "            text,\n",
        "            candidate_labels=ner_labels,\n",
        "            multi_label=True\n",
        "        )\n",
        "\n",
        "        entities = []\n",
        "\n",
        "        for label, score in zip(results['labels'], results['scores']):\n",
        "            if score > 0.5:\n",
        "                entity_type = label.split(' - ')[0]\n",
        "\n",
        "                if entity_type == \"PERSON\":\n",
        "                    pattern = r'[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*'\n",
        "                elif entity_type == \"WORK_OF_ART\":\n",
        "                    pattern = r'(?:The\\s)?[A-Z][^.!?]*?(?:movie|film|show|series)?'\n",
        "                else:\n",
        "                    pattern = r'\\b[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*'\n",
        "\n",
        "                matches = re.finditer(pattern, text)\n",
        "\n",
        "                for match in matches:\n",
        "                    entity_text = match.group()\n",
        "                    entity_confidence = self._calculate_entity_confidence(\n",
        "                        text=text,\n",
        "                        entity_text=entity_text,\n",
        "                        entity_type=entity_type,\n",
        "                        base_score=score\n",
        "                    )\n",
        "\n",
        "                    if entity_confidence > 0.6:  # Threshold for final entities\n",
        "                        entities.append({\n",
        "                            \"entity\": entity_text,\n",
        "                            \"type\": entity_type,\n",
        "                            \"confidence\": round(entity_confidence, 3)\n",
        "                        })\n",
        "\n",
        "        unique_entities = {}\n",
        "        for entity in entities:\n",
        "            key = (entity['entity'], entity['type'])\n",
        "            if key not in unique_entities or entity['confidence'] > unique_entities[key]['confidence']:\n",
        "                unique_entities[key] = entity\n",
        "\n",
        "        return {\"entities\": list(unique_entities.values())}\n",
        "\n",
        "    def _calculate_entity_confidence(self, text: str, entity_text: str,\n",
        "                                  entity_type: str, base_score: float) -> float:\n",
        "        \"\"\"Calculate confidence score for each entity based on multiple factors.\"\"\"\n",
        "        confidence = base_score\n",
        "\n",
        "        context_score = self._get_context_score(text, entity_text, entity_type)\n",
        "        confidence = confidence * 0.7 + context_score * 0.3\n",
        "\n",
        "        if len(entity_text.split()) > 1:\n",
        "            confidence *= 1.1\n",
        "\n",
        "        if entity_text.istitle():\n",
        "            confidence *= 1.1\n",
        "\n",
        "        if entity_type == \"PERSON\":\n",
        "            if len(entity_text.split()) == 2:\n",
        "                confidence *= 1.1\n",
        "            if any(title in entity_text for title in [\"Mr.\", \"Mrs.\", \"Ms.\", \"Dr.\"]):\n",
        "                confidence *= 1.1\n",
        "        elif entity_type == \"WORK_OF_ART\":\n",
        "            if \"movie\" in text.lower() or \"film\" in text.lower():\n",
        "                confidence *= 1.1\n",
        "            if any(article in entity_text for article in [\"The\", \"A\", \"An\"]):\n",
        "                confidence *= 1.05\n",
        "        elif entity_type == \"GENRE\":\n",
        "            common_genres = {\"action\", \"comedy\", \"drama\", \"horror\", \"thriller\",\n",
        "                           \"romance\", \"documentary\", \"animation\", \"sci-fi\"}\n",
        "            if entity_text.lower() in common_genres:\n",
        "                confidence *= 1.2\n",
        "        elif entity_type == \"ORG\":\n",
        "            if any(suffix in entity_text for suffix in [\"Studios\", \"Productions\", \"Entertainment\"]):\n",
        "                confidence *= 1.15\n",
        "        elif entity_type == \"ATTRIBUTE\":\n",
        "            common_attributes = {\"excellent\", \"terrible\", \"amazing\", \"boring\",\n",
        "                               \"fantastic\", \"disappointing\"}\n",
        "            if entity_text.lower() in common_attributes:\n",
        "                confidence *= 1.1\n",
        "\n",
        "        return min(max(confidence, 0.0), 1.0)\n",
        "\n",
        "    def _get_context_score(self, text: str, entity_text: str, entity_type: str) -> float:\n",
        "        \"\"\"Analyze surrounding context to adjust confidence score.\"\"\"\n",
        "        context_score = 0.7\n",
        "\n",
        "        lower_text = text.lower()\n",
        "        context_keywords = {\n",
        "            \"PERSON\": [\"actor\", \"director\", \"stars\", \"plays\", \"directed by\", \"starring\",\n",
        "                      \"performance by\", \"cast\", \"actress\", \"filmmaker\"],\n",
        "            \"WORK_OF_ART\": [\"movie\", \"film\", \"show\", \"series\", \"watched\", \"sequel\",\n",
        "                           \"trilogy\", \"adaptation\", \"premiere\", \"release\"],\n",
        "            \"ORG\": [\"studio\", \"productions\", \"entertainment\", \"pictures\", \"company\",\n",
        "                   \"distributor\", \"producer\", \"corporation\"],\n",
        "            \"GENRE\": [\"genre\", \"type of\", \"kind of\", \"similar to\", \"category\",\n",
        "                     \"style of\", \"like other\"],\n",
        "            \"ATTRIBUTE\": [\"rating\", \"review\", \"quality\", \"style\", \"performance\",\n",
        "                         \"visual\", \"story\", \"plot\", \"acting\", \"effects\"]\n",
        "        }\n",
        "\n",
        "        keywords = context_keywords.get(entity_type, [])\n",
        "        for keyword in keywords:\n",
        "            if keyword in lower_text:\n",
        "                context_score += 0.1\n",
        "\n",
        "        entity_position = text.find(entity_text)\n",
        "        if entity_position != -1:\n",
        "            context_window = text[max(0, entity_position-30):\n",
        "                                min(len(text), entity_position+30)]\n",
        "            for keyword in keywords:\n",
        "                if keyword in context_window.lower():\n",
        "                    context_score += 0.15\n",
        "\n",
        "        sentences = text.split('.')\n",
        "        for sentence in sentences:\n",
        "            if entity_text in sentence:\n",
        "                if any(keyword in sentence.lower() for keyword in keywords):\n",
        "                    context_score += 0.1\n",
        "\n",
        "        return min(context_score, 1.0)\n",
        "\n",
        "    def _analyze_message(self, message_id: int, conversation_id: str, text: str,\n",
        "                        original_text: str, time_offset: int,\n",
        "                        referenced_movies: List[str]) -> MessageAnalysisResult:\n",
        "        \"\"\"Analyze a single message for intent and entities.\"\"\"\n",
        "        try:\n",
        "            entity_results = self._process_with_prompt_ner(text, self.entity_prompt_template.format(text=text))\n",
        "            intent_results = self._process_with_prompt_intent(text, self.intent_prompt_template.format(text=text))\n",
        "\n",
        "            return MessageAnalysisResult(\n",
        "                message_id=message_id,\n",
        "                conversation_id=conversation_id,\n",
        "                text=original_text,\n",
        "                time_offset=time_offset,\n",
        "                intent=intent_results['intent'],\n",
        "                confidence=intent_results['confidence'],\n",
        "                entities=entity_results['entities'],\n",
        "                referenced_movies=referenced_movies,\n",
        "                analysis_details={'processed_text': text}\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in message analysis: {str(e)}\")\n",
        "            return MessageAnalysisResult(\n",
        "                message_id=message_id,\n",
        "                conversation_id=conversation_id,\n",
        "                text=original_text,\n",
        "                time_offset=time_offset,\n",
        "                intent=\"unknown\",\n",
        "                confidence=0.0,\n",
        "                entities=[],\n",
        "                referenced_movies=referenced_movies,\n",
        "                analysis_details={'error': str(e)}\n",
        "            )\n",
        "\n",
        "    def process_jsonl_file(self, input_file: str, batch_size: int = 4) -> List[MessageAnalysisResult]:\n",
        "        \"\"\"Process entire JSONL file and analyze all messages.\"\"\"\n",
        "        all_results = []\n",
        "        self.logger.info(f\"Processing JSONL file: {input_file}\")\n",
        "\n",
        "        try:\n",
        "            with jsonlines.open(input_file) as reader:\n",
        "                dialogues = list(reader)\n",
        "\n",
        "            for start in tqdm(range(0, len(dialogues), batch_size)):\n",
        "                batch = dialogues[start:start + batch_size]\n",
        "                for dialogue in batch:\n",
        "                    dialogue_results = self._process_dialogue(dialogue)\n",
        "                    all_results.extend(dialogue_results)\n",
        "\n",
        "            self.logger.info(f\"Processed {len(all_results)} messages from {len(dialogues)} dialogues\")\n",
        "            return all_results\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing JSONL file: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def export_results_to_csv(self, results: List[MessageAnalysisResult], output_file: str) -> None:\n",
        "        \"\"\"Export analysis results to a CSV file with confidence scores.\"\"\"\n",
        "        self.logger.info(f\"Exporting results to CSV file: {output_file}\")\n",
        "\n",
        "        try:\n",
        "            data = [{\n",
        "                \"message_id\": result.message_id,\n",
        "                \"conversation_id\": result.conversation_id,\n",
        "                \"text\": result.text,\n",
        "                \"time_offset\": result.time_offset,\n",
        "                \"intent\": result.intent,\n",
        "                \"intent_confidence\": result.confidence,\n",
        "                \"entities\": json.dumps(result.entities),\n",
        "                \"referenced_movies\": json.dumps(result.referenced_movies),\n",
        "                \"processed_text\": result.analysis_details.get('processed_text', ''),\n",
        "                \"error\": result.analysis_details.get('error', '')\n",
        "            } for result in results]\n",
        "\n",
        "            df = pd.DataFrame(data)\n",
        "            df.to_csv(output_file, index=False)\n",
        "\n",
        "            self.logger.info(f\"Exported {len(results)} results to {output_file}\")\n",
        "            self.logger.info(f\"Average intent confidence: {df['intent_confidence'].mean():.3f}\")\n",
        "\n",
        "            entity_counts = df['entities'].apply(json.loads).apply(len)\n",
        "            self.logger.info(f\"Average entities per message: {entity_counts.mean():.2f}\")\n",
        "\n",
        "            self.logger.info(\"Results exported successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error exporting results to CSV: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def get_statistics(self, results: List[MessageAnalysisResult]) -> Dict:\n",
        "        \"\"\"Generate statistics about the analysis results.\"\"\"\n",
        "        try:\n",
        "            total_messages = len(results)\n",
        "            total_entities = sum(len(result.entities) for result in results)\n",
        "\n",
        "            intent_distribution = {}\n",
        "            for result in results:\n",
        "                intent_distribution[result.intent] = intent_distribution.get(result.intent, 0) + 1\n",
        "\n",
        "            entity_type_distribution = {}\n",
        "            entity_confidence_by_type = {}\n",
        "            for result in results:\n",
        "                for entity in result.entities:\n",
        "                    entity_type = entity['type']\n",
        "                    entity_type_distribution[entity_type] = entity_type_distribution.get(entity_type, 0) + 1\n",
        "\n",
        "                    if entity_type not in entity_confidence_by_type:\n",
        "                        entity_confidence_by_type[entity_type] = []\n",
        "                    entity_confidence_by_type[entity_type].append(entity['confidence'])\n",
        "\n",
        "            avg_confidence_by_type = {\n",
        "                entity_type: sum(confidences) / len(confidences)\n",
        "                for entity_type, confidences in entity_confidence_by_type.items()\n",
        "            }\n",
        "\n",
        "            return {\n",
        "                \"total_messages\": total_messages,\n",
        "                \"total_entities\": total_entities,\n",
        "                \"avg_entities_per_message\": total_entities / total_messages if total_messages > 0 else 0,\n",
        "                \"intent_distribution\": intent_distribution,\n",
        "                \"entity_type_distribution\": entity_type_distribution,\n",
        "                \"avg_confidence_by_type\": avg_confidence_by_type\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generating statistics: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "def main(input_file: str, output_file: str, batch_size: int = 4):\n",
        "    \"\"\"Main function to run the movie dialog analysis.\"\"\"\n",
        "    try:\n",
        "        analyzer = MovieDialogAnalyzer()\n",
        "        results = analyzer.process_jsonl_file(input_file, batch_size=batch_size)\n",
        "\n",
        "        analyzer.export_results_to_csv(results, output_file)\n",
        "\n",
        "        stats = analyzer.get_statistics(results)\n",
        "        print(\"\\nAnalysis Statistics:\")\n",
        "        print(f\"Total messages processed: {stats['total_messages']}\")\n",
        "        print(f\"Total entities found: {stats['total_entities']}\")\n",
        "        print(f\"Average entities per message: {stats['avg_entities_per_message']:.2f}\")\n",
        "\n",
        "        print(\"\\nIntent Distribution:\")\n",
        "        for intent, count in stats['intent_distribution'].items():\n",
        "            print(f\"{intent}: {count}\")\n",
        "\n",
        "        print(\"\\nEntity Type Distribution:\")\n",
        "        for entity_type, count in stats['entity_type_distribution'].items():\n",
        "            print(f\"{entity_type}: {count} (Avg confidence: {stats['avg_confidence_by_type'][entity_type]:.3f})\")\n",
        "\n",
        "        print(\"\\nProcessing and export completed successfully.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = 'train.jsonl'  # Input JSONL file path\n",
        "    output_file = 'analysis_results.csv'  # Output CSV file path\n",
        "    main(input_file, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cmKjILiUHYv",
        "outputId": "e49789ee-d822-484c-c7ed-621d37ade1b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-07 07:02:00,915 - __main__ - INFO - Setting up models...\n",
            "2024-11-07 07:02:00,915 - __main__ - INFO - Setting up models...\n",
            "2024-11-07 07:02:00,915 - __main__ - INFO - Setting up models...\n",
            "2024-11-07 07:02:00,915 - __main__ - INFO - Setting up models...\n",
            "2024-11-07 07:02:00,915 - __main__ - INFO - Setting up models...\n",
            "2024-11-07 07:02:00,915 - __main__ - INFO - Setting up models...\n",
            "2024-11-07 07:02:00,915 - __main__ - INFO - Setting up models...\n",
            "INFO:__main__:Setting up models...\n",
            "2024-11-07 07:02:04,580 - __main__ - INFO - Models loaded successfully\n",
            "2024-11-07 07:02:04,580 - __main__ - INFO - Models loaded successfully\n",
            "2024-11-07 07:02:04,580 - __main__ - INFO - Models loaded successfully\n",
            "2024-11-07 07:02:04,580 - __main__ - INFO - Models loaded successfully\n",
            "2024-11-07 07:02:04,580 - __main__ - INFO - Models loaded successfully\n",
            "2024-11-07 07:02:04,580 - __main__ - INFO - Models loaded successfully\n",
            "2024-11-07 07:02:04,580 - __main__ - INFO - Models loaded successfully\n",
            "INFO:__main__:Models loaded successfully\n",
            "2024-11-07 07:02:04,607 - __main__ - INFO - Processing JSONL file: train.jsonl\n",
            "2024-11-07 07:02:04,607 - __main__ - INFO - Processing JSONL file: train.jsonl\n",
            "2024-11-07 07:02:04,607 - __main__ - INFO - Processing JSONL file: train.jsonl\n",
            "2024-11-07 07:02:04,607 - __main__ - INFO - Processing JSONL file: train.jsonl\n",
            "2024-11-07 07:02:04,607 - __main__ - INFO - Processing JSONL file: train.jsonl\n",
            "2024-11-07 07:02:04,607 - __main__ - INFO - Processing JSONL file: train.jsonl\n",
            "2024-11-07 07:02:04,607 - __main__ - INFO - Processing JSONL file: train.jsonl\n",
            "INFO:__main__:Processing JSONL file: train.jsonl\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]2024-11-07 07:02:04,633 - __main__ - WARNING - No initiator ID found for dialogue 391\n",
            "2024-11-07 07:02:04,633 - __main__ - WARNING - No initiator ID found for dialogue 391\n",
            "2024-11-07 07:02:04,633 - __main__ - WARNING - No initiator ID found for dialogue 391\n",
            "2024-11-07 07:02:04,633 - __main__ - WARNING - No initiator ID found for dialogue 391\n",
            "2024-11-07 07:02:04,633 - __main__ - WARNING - No initiator ID found for dialogue 391\n",
            "2024-11-07 07:02:04,633 - __main__ - WARNING - No initiator ID found for dialogue 391\n",
            "2024-11-07 07:02:04,633 - __main__ - WARNING - No initiator ID found for dialogue 391\n",
            "WARNING:__main__:No initiator ID found for dialogue 391\n",
            "100%|██████████| 1/1 [04:00<00:00, 240.94s/it]\n",
            "2024-11-07 07:06:05,577 - __main__ - INFO - Processed 21 messages from 3 dialogues\n",
            "2024-11-07 07:06:05,577 - __main__ - INFO - Processed 21 messages from 3 dialogues\n",
            "2024-11-07 07:06:05,577 - __main__ - INFO - Processed 21 messages from 3 dialogues\n",
            "2024-11-07 07:06:05,577 - __main__ - INFO - Processed 21 messages from 3 dialogues\n",
            "2024-11-07 07:06:05,577 - __main__ - INFO - Processed 21 messages from 3 dialogues\n",
            "2024-11-07 07:06:05,577 - __main__ - INFO - Processed 21 messages from 3 dialogues\n",
            "2024-11-07 07:06:05,577 - __main__ - INFO - Processed 21 messages from 3 dialogues\n",
            "INFO:__main__:Processed 21 messages from 3 dialogues\n",
            "2024-11-07 07:06:05,593 - __main__ - INFO - Exporting results to CSV file: analysis_results.csv\n",
            "2024-11-07 07:06:05,593 - __main__ - INFO - Exporting results to CSV file: analysis_results.csv\n",
            "2024-11-07 07:06:05,593 - __main__ - INFO - Exporting results to CSV file: analysis_results.csv\n",
            "2024-11-07 07:06:05,593 - __main__ - INFO - Exporting results to CSV file: analysis_results.csv\n",
            "2024-11-07 07:06:05,593 - __main__ - INFO - Exporting results to CSV file: analysis_results.csv\n",
            "2024-11-07 07:06:05,593 - __main__ - INFO - Exporting results to CSV file: analysis_results.csv\n",
            "2024-11-07 07:06:05,593 - __main__ - INFO - Exporting results to CSV file: analysis_results.csv\n",
            "INFO:__main__:Exporting results to CSV file: analysis_results.csv\n",
            "2024-11-07 07:06:05,624 - __main__ - INFO - Exported 21 results to analysis_results.csv\n",
            "2024-11-07 07:06:05,624 - __main__ - INFO - Exported 21 results to analysis_results.csv\n",
            "2024-11-07 07:06:05,624 - __main__ - INFO - Exported 21 results to analysis_results.csv\n",
            "2024-11-07 07:06:05,624 - __main__ - INFO - Exported 21 results to analysis_results.csv\n",
            "2024-11-07 07:06:05,624 - __main__ - INFO - Exported 21 results to analysis_results.csv\n",
            "2024-11-07 07:06:05,624 - __main__ - INFO - Exported 21 results to analysis_results.csv\n",
            "2024-11-07 07:06:05,624 - __main__ - INFO - Exported 21 results to analysis_results.csv\n",
            "INFO:__main__:Exported 21 results to analysis_results.csv\n",
            "2024-11-07 07:06:05,641 - __main__ - INFO - Average intent confidence: 0.272\n",
            "2024-11-07 07:06:05,641 - __main__ - INFO - Average intent confidence: 0.272\n",
            "2024-11-07 07:06:05,641 - __main__ - INFO - Average intent confidence: 0.272\n",
            "2024-11-07 07:06:05,641 - __main__ - INFO - Average intent confidence: 0.272\n",
            "2024-11-07 07:06:05,641 - __main__ - INFO - Average intent confidence: 0.272\n",
            "2024-11-07 07:06:05,641 - __main__ - INFO - Average intent confidence: 0.272\n",
            "2024-11-07 07:06:05,641 - __main__ - INFO - Average intent confidence: 0.272\n",
            "INFO:__main__:Average intent confidence: 0.272\n",
            "2024-11-07 07:06:05,653 - __main__ - INFO - Average entities per message: 3.38\n",
            "2024-11-07 07:06:05,653 - __main__ - INFO - Average entities per message: 3.38\n",
            "2024-11-07 07:06:05,653 - __main__ - INFO - Average entities per message: 3.38\n",
            "2024-11-07 07:06:05,653 - __main__ - INFO - Average entities per message: 3.38\n",
            "2024-11-07 07:06:05,653 - __main__ - INFO - Average entities per message: 3.38\n",
            "2024-11-07 07:06:05,653 - __main__ - INFO - Average entities per message: 3.38\n",
            "2024-11-07 07:06:05,653 - __main__ - INFO - Average entities per message: 3.38\n",
            "INFO:__main__:Average entities per message: 3.38\n",
            "2024-11-07 07:06:05,664 - __main__ - INFO - Results exported successfully\n",
            "2024-11-07 07:06:05,664 - __main__ - INFO - Results exported successfully\n",
            "2024-11-07 07:06:05,664 - __main__ - INFO - Results exported successfully\n",
            "2024-11-07 07:06:05,664 - __main__ - INFO - Results exported successfully\n",
            "2024-11-07 07:06:05,664 - __main__ - INFO - Results exported successfully\n",
            "2024-11-07 07:06:05,664 - __main__ - INFO - Results exported successfully\n",
            "2024-11-07 07:06:05,664 - __main__ - INFO - Results exported successfully\n",
            "INFO:__main__:Results exported successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analysis Statistics:\n",
            "Total messages processed: 21\n",
            "Total entities found: 71\n",
            "Average entities per message: 3.38\n",
            "\n",
            "Intent Distribution:\n",
            "Ask for Recommendation: 5\n",
            "Feedback on Recommendation: 2\n",
            "Obtain Explanation: 3\n",
            "Provide Preferences: 4\n",
            "Accept Recommendation: 6\n",
            "Chit-chat: 1\n",
            "\n",
            "Entity Type Distribution:\n",
            "ATTRIBUTE: 52 (Avg confidence: 0.940)\n",
            "GENRE: 19 (Avg confidence: 0.857)\n",
            "\n",
            "Processing and export completed successfully.\n"
          ]
        }
      ]
    }
  ]
}